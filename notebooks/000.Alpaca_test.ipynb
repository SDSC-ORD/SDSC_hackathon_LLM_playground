{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b15f201b-f749-4870-83a3-baf9ac67cb1b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37cb4619",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://datascience.ch/wp-content/uploads/2020/09/logo-SDSC-transparent.png\" alt=\"SDSC\" width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83217991-40a4-4f0c-83cb-203783f09adc",
   "metadata": {},
   "source": [
    "# SDSC Alpaca Test\n",
    "Maintained by [carlos.vivarrios@epfl.ch](carlos.vivarrios@epfl.ch)\n",
    "\n",
    "In this notebook we show a simple way to have a model for text to text (TTT) generation. (In theory) Any TTT transformer model in [Huggingface.co](https://huggingface.co/models?pipeline_tag=text2text-generation&sort=downloads) can be used by passing its path to the `model` parameter. \n",
    "\n",
    "The first time you execute `pipeline` the model will be automatically downloaded and loaded into memory. After running it, do not forget to shutdown your kernel, otherwise the model will remain in the GPU memory. \n",
    "\n",
    "Usually models ara available in different sizes or trained on different datasets. \n",
    "\n",
    "Model | Parameters | Instruction Data\n",
    "--- | --- | ---\n",
    "flan-alpaca-base | 220M | Flan, Alpaca\n",
    "flan-alpaca-large | 770M | Flan, Alpaca\n",
    "flan-alpaca-XL | 3B | Flan, Alpaca\n",
    "\n",
    "In the terminal you can check how much VRAM is being allocated by a model by using `nvitop`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5e04228-5a0d-4004-ad97-17f384203008",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3692b6-44a7-4c07-bf54-6d5a1cbb9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8b1b2-c684-4b5b-aebc-220f344d2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(model=\"declare-lab/flan-alpaca-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712127b9-d5ac-4d03-a517-05c8926179cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write an email about an alpaca that likes flan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7193f-f09e-41c7-8dd3-33db8b3fb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(prompt, max_length=128, do_sample=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b85fad0-65b4-4ca4-8681-62a2814ad529",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8009dbf9-56df-493f-a1e1-445fcfee7ebe",
   "metadata": {},
   "source": [
    "SDSC Large Language Model Playground.\n",
    "\n",
    "Created with ❤️ by ORDES SDSC Team. 2023. \n",
    "\n",
    "Maintained by [carlos.vivarrios@epfl.ch](carlos.vivarrios@epfl.ch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49c039ab-b106-4275-8ccd-0b629772c53e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
