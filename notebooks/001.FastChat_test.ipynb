{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://datascience.ch/wp-content/uploads/2020/09/logo-SDSC-transparent.png\" alt=\"SDSC\" width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDSC Alpaca Test\n",
    "\n",
    "This tutorial has been adapted from [Fast Chat Langchain integration](https://github.com/lm-sys/FastChat/blob/main/docs/langchain_integration.md)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local LangChain with FastChat\n",
    "\n",
    "[LangChain](https://python.langchain.com/en/latest/index.html) is a library that facilitates the development of applications by leveraging large language models (LLMs) and enabling their composition with other sources of computation or knowledge.\n",
    "FastChat's OpenAI-compatible [API server](openai_api.md) enables using LangChain with open models seamlessly.\n",
    "\n",
    "## Launch RESTful API Server\n",
    "\n",
    "Here are the steps to launch a local OpenAI API server for LangChain.\n",
    "\n",
    "First, launch the controller\n",
    "\n",
    "```bash\n",
    "python3 -m fastchat.serve.controller\n",
    "```\n",
    "\n",
    "Due to the fact that langchain checks whether the model's name belongs to OpenAI, we need to assign a faux OpenAI name to the Vicuna model. In essence, we're providing an OpenAI model name when loading the model.\n",
    "Replace `/path/to/weights` below with the a real path to a local model such as Vicuna. It can also be a Hugging Face repo id such as `lmsys/fastchat-t5-3b-v1.0`.\n",
    "\n",
    "```bash\n",
    "python3 -m fastchat.serve.model_worker --model-names \"gpt-3.5-turbo,text-davinci-003,text-embedding-ada-002\" --model-path /path/to/weights\n",
    "```\n",
    "\n",
    "Finally, launch the RESTful API server\n",
    "\n",
    "```bash\n",
    "python3 -m fastchat.serve.openai_api_server --host localhost --port 8000\n",
    "```\n",
    "\n",
    "## Set OpenAI Environment\n",
    "\n",
    "You can set your environment with the following commands.\n",
    "\n",
    "Set OpenAI base url\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_BASE=http://localhost:8000/v1\n",
    "```\n",
    "\n",
    "Set OpenAI API key\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=EMPTY\n",
    "```\n",
    "\n",
    "## Try local LangChain\n",
    "\n",
    "Here is a question answerting example.\n",
    "\n",
    "~~~py\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "# wget https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\n",
    "loader = TextLoader('state_of_the_union.txt')\n",
    "index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "questions = [\n",
    "             \"who is the speaker\", \n",
    "             \"What did the president say about Ketanji Brown Jackson\", \n",
    "             \"What are the threats to America\", \n",
    "             \"Who are mentioned in the speech\",\n",
    "             \"Who is the vice president\",\n",
    "             \"How many projects were announced\",\n",
    "            ]\n",
    "\n",
    "for query in questions:\n",
    "    print(\"Query: \", query)\n",
    "    print(\"Ans: \",index.query(query,llm=llm))\n",
    "~~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDSC Large Language Model Playground.\n",
    "\n",
    "Created with ❤️ by ORDES SDSC Team. 2023. \n",
    "\n",
    "Maintained by [carlos.vivarrios@epfl.ch](carlos.vivarrios@epfl.ch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
